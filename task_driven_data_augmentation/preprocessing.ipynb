{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing.ipynb","provenance":[],"authorship_tag":"ABX9TyM4gyL2oulKmjJqK3+3z7It"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"uVqiTiaONRcj","colab_type":"code","colab":{}},"source":["# Mount Google Drive\n","%%capture\n","from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive\"     # default location for the drive\n","\n","drive.mount(ROOT);           # we mount the google drive at /content/drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OztsIc5yNSK-","colab_type":"code","colab":{}},"source":["# Set working directory\n","%%capture\n","%cd /content/drive/My Drive/restoration-mapper/task_driven_data_augmentation"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o5j9lQDaNMEj","colab_type":"code","colab":{}},"source":["'''\n","This script is to preprocess all the data into the chosen resolution and fixed dimensions specified in the init_acdc.py config file.\n","This re-sampled (to target resolution) and cropped/zero-padded image,label pairs are stored in npy files and are later used directly while the training of the network.\n","'''\n","import numpy as np\n","import pathlib"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hay8CRqANQap","colab_type":"code","colab":{}},"source":["class params:\n","  dataset = 'acdc'\n","  #no of training images\n","  no_of_tr_imgs = 'tr3' # Options include: ['tr1', 'tr3', 'tr5', 'tr15', 'tr40']\n","  #combination of training images\n","  comb_tr_imgs = 'c1' # Options include: ['c1', 'c2', 'c3', 'c4', 'c5']\n","\n","  #learning rate of seg unet\n","  lr_seg = 0.001\n","  # learning rate of generator\n","  lr_gen = 0.0001\n","  # learning rate of discriminator\n","  lr_disc = 0.0001\n","  # lat dim of z sample\n","  z_lat_dim = 100\n","\n","  # ra_en : 0 - disabled, 1 - enabled\n","  ra_en = 0\n","  # select gan type\n","  gan_type = 'gan' # Options include: ['lsgan', 'gan', 'wgan-gp','ngan']\n","  # beta value of Adam optimizer\n","  beta_val = 0.9\n","  # to enable the representation of labels with 1 hot encoding\n","  en_1hot = 1\n","\n","  # lamda factors\n","  # for segmenation loss term (lamda_dsc)\n","  lamda_dsc = 1\n","  # adversarial loss term (lamda_adv)\n","  lamda_adv = 1\n","  ### deformation field cGAN specific\n","  # for negative L1 loss on spatial transformation (per-pixel flow field/deformation field) term (lamda_l1_g)\n","  lamda_l1_g = 0.001\n","\n","  ### Intensity field cGAN specific\n","  # for negative L1 loss on transformation (additive intensity field) term (lamda_l1_i)\n","  lamda_l1_i = 0.001\n","\n","  #version of run\n","  ver = 0\n","\n","  #data aug - 0 - disabled, 1 - enabled\n","  data_aug_seg = 1 # Options include: [0,1]\n","\n","  # segmentation loss to optimize\n","  # 0 for weighted cross entropy, 1 for dice score loss\n","  dsc_loss = 0 # Options include: [0,1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNsyCTfbM00i","colab_type":"code","colab":{}},"source":["######################################\n","# create cropped images\n","# ####################################\n","if params.dataset == 'acdc':\n","    #print('load acdc configs')\n","    import experiment_init.init_acdc as cfg\n","    import experiment_init.data_cfg_acdc as data_list\n","else:\n","    raise ValueError(params.dataset)\n","\n","from dataloaders import dataloaderObj\n","dt = dataloaderObj(cfg)\n","\n","if params.dataset == 'acdc':\n","    #print('set acdc orig img dataloader handle')\n","    orig_img_dt=dt.load_acdc_imgs\n","\n","#loop over all image,label pairs to create cropped image,label pairs\n","for index in range(1,101):\n","    # Load each image\n","    if(index<10):\n","        test_id='00'+str(index)\n","    elif(index<100):\n","        test_id='0'+str(index)\n","    else:\n","        test_id=str(index)\n","    test_id_l=[test_id]\n","\n","    #load image,label pairs and process it to chosen resolution and dimensions    \n","    img_sys,label_sys,pixel_size,affine_tst= orig_img_dt(test_id_l,ret_affine=1)\n","    cropped_img_sys,cropped_mask_sys = dt.preprocess_data(img_sys, label_sys, pixel_size)\n","\n","    #save the processed cropped img and its label\n","    save_dir_tmp=str(cfg.data_path_tr_cropped)+str(test_id)+'/'\n","    pathlib.Path(save_dir_tmp).mkdir(parents=True, exist_ok=True)\n","    savefile_name=str(save_dir_tmp)+'img_cropped.npy' \n","    np.save(savefile_name,cropped_img_sys)\n","    savefile_name=str(save_dir_tmp)+'mask_cropped.npy' \n","    np.save(savefile_name,cropped_mask_sys)"],"execution_count":0,"outputs":[]}]}
