{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "1-load-data-yale.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KaKniKAgQrL",
        "colab_type": "text"
      },
      "source": [
        "# Start here if working in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVUplr8ocxt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c60a080d-b6a9-4738-f976-dfa7d64be81e"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaDwqC7QeFsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72ba8e82-774a-4cb8-e7dd-38d67309d58d"
      },
      "source": [
        "# Set working directory\n",
        "%cd drive/My Drive/restoration-mapper"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mnotebooks\u001b[0m/  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PPyAQ8QcxuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook, tnrange\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "import pandas as pd\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXnAjC-mgcMe",
        "colab_type": "text"
      },
      "source": [
        "# Start here if working locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipQlldfIcxuX",
        "colab_type": "text"
      },
      "source": [
        "### Additional function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ervfg9A8cxuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstruct_images(plot_id):\n",
        "    '''\n",
        "    Takes a plot ID and subsets the input pd.DataFrame to that plot ID\n",
        "    returns a (14, 14) array-like list with binary labels\n",
        "    # LAT, LONG, TREE\n",
        "    # 42.11, 1.02, 0\n",
        "    # 42.1102, 1.02, 1\n",
        "    \n",
        "    '''\n",
        "    subs = df[df['PLOT_ID'] == plot_id]\n",
        "    rows = []\n",
        "    lats = reversed(sorted(subs['LAT'].unique()))\n",
        "    for i, val in enumerate(lats):\n",
        "        subs_lat = subs[subs['LAT'] == val]\n",
        "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
        "        rows.append(list(subs_lat['TREE']))\n",
        "    return rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGnHqn4Scxuf",
        "colab_type": "text"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPr7EkEocxuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source = 'test'\n",
        "sentinel_1 = True\n",
        "s2_path = \"../{}-super/\".format(source)\n",
        "s1_path = \"../{}-s1/\".format(source)\n",
        "csv_path = \"../{}-csv/\".format(source)\n",
        "output_path = \"../{}-processed/\".format(source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UROR2LHncxum",
        "colab_type": "code",
        "colab": {},
        "outputId": "ab7ab5b2-4481-40f7-cb23-0768ad56eab3"
      },
      "source": [
        "# For either train or test data, loop through each plot and determine whether there is\n",
        "# labelled Y data for it -- returning one dataframe for the entire data set\n",
        "\n",
        "dfs = []\n",
        "for i in os.listdir(csv_path):\n",
        "    if \".csv\" in i:\n",
        "        print(i)\n",
        "        df = pd.read_csv(csv_path + i).drop('IMAGERY_TITLE', axis = 1)\n",
        "        df['country'] = i.split(\".\")[0]\n",
        "        dfs.append(df)\n",
        "\n",
        "for i in range(len(dfs)):\n",
        "    if \"PL_PLOTID\" in dfs[i].columns:\n",
        "            dfs[i] = dfs[i].drop(\"PL_PLOTID\", axis = 1)\n",
        "    if 'STACKINGPROFILEDG' in dfs[i].columns:\n",
        "        dfs[i] = dfs[i].drop('STACKINGPROFILEDG', axis = 1)\n",
        "    if 'IMAGERYYEARDG' in dfs[i].columns:\n",
        "        dfs[i] = dfs[i].drop('IMAGERYYEARDG', axis = 1)\n",
        "\n",
        "df = pd.concat(dfs, ignore_index = True)\n",
        "df = df.dropna(axis = 0)\n",
        "\n",
        "existing = [int(x[:-4]) for x in os.listdir(s2_path) if \".DS\" not in x]\n",
        "df = df[df['PLOT_ID'].isin(existing)]\n",
        "plot_ids = sorted(df['PLOT_ID'].unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "india-test.csv\n",
            "lac-north-test.csv\n",
            "cameroon-test.csv\n",
            "ghana-test.csv\n",
            "global-test.csv\n",
            "kenya-test.csv\n",
            "lac-south-test.csv\n",
            "ethiopia-test.csv\n",
            "ghana-test-large.csv\n",
            "africaeast-test.csv\n",
            "africawest-test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uql1oSrFcxuu",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "cc8d8bd188df427fbb17df0fdbcc30ad"
          ]
        },
        "outputId": "bd276b5b-0d92-47b7-979a-d713dbf766ab"
      },
      "source": [
        "# Initiate empty lists to store the X and Y data in\n",
        "data_x, data_y, lengths = [], [], []\n",
        "    \n",
        "    \n",
        "countries = {}\n",
        "count = 0\n",
        "to_remove = []\n",
        "# Iterate over each plot\n",
        "for i in tnrange(len(plot_ids)):\n",
        "    skip = True if sentinel_1 else False\n",
        "    # Load the sentinel imagery\n",
        "    if (str(plot_ids[i]) + \".npy\")in os.listdir(s2_path):\n",
        "        country = df[df['PLOT_ID'] == plot_ids[i]]['country'].unique()\n",
        "        if str(country[0]) not in countries.keys():\n",
        "            countries[str(country[0])] = [count, count]\n",
        "        countries[str(country[0])][1] = count\n",
        "        x = np.load(s2_path + str(plot_ids[i]) + \".npy\")\n",
        "        if sentinel_1 and os.path.isfile(s1_path + str(plot_ids[i]) + \".npy\"):\n",
        "            skip = False\n",
        "            s1 = np.load(s1_path + str(plot_ids[i]) + \".npy\")\n",
        "            x = np.concatenate([x, s1], axis = -1)\n",
        "        count += 1\n",
        "    y = reconstruct_images(plot_ids[i])\n",
        "    if not skip:\n",
        "        lengths.append(x.shape[0])\n",
        "        data_x.append(x)\n",
        "        data_y.append(y)\n",
        "print(\"Finished data loading\")\n",
        "\n",
        "data_x = np.stack(data_x)\n",
        "data_y = np.stack(data_y)\n",
        "lengths = np.stack(lengths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc8d8bd188df427fbb17df0fdbcc30ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=684), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished data loading\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYXJm7NMcxu4",
        "colab_type": "text"
      },
      "source": [
        "### Data writing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3NSzQ9cxu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This writes a (N_samples, time, width, height, channels) X data that is not standardized\n",
        "# Training 4500, 24, 16, 16, 16\n",
        "# and a (N_samples, width, height) Y data where the Y is a 0 / 1 binary tree presence\n",
        "# The X data is 16x16, and the Y data is 14x14 -- so the X data incorporates an extra boundary\n",
        "# pixel, which should be downsampled before output layer with a convolution layer with no padding\n",
        "\n",
        "# The X data channels are as below:\n",
        "# [B02,B03,B04,B05,B06,B07, B08, B8A,B11,B12, SLOPE, EVI, MSAVI2, Bare soil index,\n",
        "#    Sentinel 1 VV, Sentinel 1 VH]\n",
        "\n",
        "# GAN \n",
        "\n",
        "# Pretraining\n",
        "\n",
        "# Normalization\n",
        "#     layer norm,\n",
        "#     batch renorm\n",
        "#     batch norm, batch renormalization, instance normalization,\n",
        "#     self normalization - https://arxiv.org/abs/1706.02515\n",
        "\n",
        "# Loss functions\n",
        "#   - binary cross entropy\n",
        "#   - boundary loss\n",
        "#   - lovasz softmax\n",
        "#   - directly optimize dice score\n",
        "#   - hausdorff distance metrics\n",
        "#   - focal loss\n",
        "\n",
        "# Baseline ResNet, InceptionNet, XceptionNet\n",
        "\n",
        "\n",
        "if source == 'train':\n",
        "    np.save(output_path + \"data_x_l2a_processed.npy\", data_x)\n",
        "    np.save(output_path + \"data_y_l2a_processed.npy\", np.array(data_y))\n",
        "    np.save(output_path + \"length_l2a_processed.npy\", np.array(lengths))\n",
        "if source == 'test' or source == \"project\":\n",
        "    print(\"Writing test data\")\n",
        "    np.save(output_path + \"test_x_l2a_processed.npy\", data_x)\n",
        "    np.save(output_path + \"test_y_l2a_processed.npy\", data_y)\n",
        "    np.save(output_path + \"test_length_l2a_processed.npy\", lengths)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}