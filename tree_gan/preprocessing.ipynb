{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVqiTiaONRcj"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "%%capture\n",
    "from google.colab import drive # import drive from google colab\n",
    "\n",
    "ROOT = \"/content/drive\"     # default location for the drive\n",
    "\n",
    "drive.mount(ROOT);           # we mount the google drive at /content/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OztsIc5yNSK-"
   },
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "%%capture\n",
    "%cd /content/drive/My Drive/restoration-mapper/task_driven_data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5j9lQDaNMEj"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This script is to preprocess all the data into the chosen resolution and fixed dimensions specified in the init_acdc.py config file.\n",
    "This re-sampled (to target resolution) and cropped/zero-padded image,label pairs are stored in npy files and are later used directly while the training of the network.\n",
    "'''\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hay8CRqANQap"
   },
   "outputs": [],
   "source": [
    "class params:\n",
    "  dataset = 'acdc'\n",
    "  #no of training images\n",
    "  no_of_tr_imgs = 'tr3' # Options include: ['tr1', 'tr3', 'tr5', 'tr15', 'tr40']\n",
    "  #combination of training images\n",
    "  comb_tr_imgs = 'c1' # Options include: ['c1', 'c2', 'c3', 'c4', 'c5']\n",
    "\n",
    "  #learning rate of seg unet\n",
    "  lr_seg = 0.001\n",
    "  # learning rate of generator\n",
    "  lr_gen = 0.0001\n",
    "  # learning rate of discriminator\n",
    "  lr_disc = 0.0001\n",
    "  # lat dim of z sample\n",
    "  z_lat_dim = 100\n",
    "\n",
    "  # ra_en : 0 - disabled, 1 - enabled\n",
    "  ra_en = 0\n",
    "  # select gan type\n",
    "  gan_type = 'gan' # Options include: ['lsgan', 'gan', 'wgan-gp','ngan']\n",
    "  # beta value of Adam optimizer\n",
    "  beta_val = 0.9\n",
    "  # to enable the representation of labels with 1 hot encoding\n",
    "  en_1hot = 1\n",
    "\n",
    "  # lamda factors\n",
    "  # for segmenation loss term (lamda_dsc)\n",
    "  lamda_dsc = 1\n",
    "  # adversarial loss term (lamda_adv)\n",
    "  lamda_adv = 1\n",
    "  ### deformation field cGAN specific\n",
    "  # for negative L1 loss on spatial transformation (per-pixel flow field/deformation field) term (lamda_l1_g)\n",
    "  lamda_l1_g = 0.001\n",
    "\n",
    "  ### Intensity field cGAN specific\n",
    "  # for negative L1 loss on transformation (additive intensity field) term (lamda_l1_i)\n",
    "  lamda_l1_i = 0.001\n",
    "\n",
    "  #version of run\n",
    "  ver = 0\n",
    "\n",
    "  #data aug - 0 - disabled, 1 - enabled\n",
    "  data_aug_seg = 1 # Options include: [0,1]\n",
    "\n",
    "  # segmentation loss to optimize\n",
    "  # 0 for weighted cross entropy, 1 for dice score loss\n",
    "  dsc_loss = 0 # Options include: [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNsyCTfbM00i"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# create cropped images\n",
    "# ####################################\n",
    "if params.dataset == 'acdc':\n",
    "    #print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('set acdc orig img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#loop over all image,label pairs to create cropped image,label pairs\n",
    "for index in range(1,101):\n",
    "    # Load each image\n",
    "    if(index<10):\n",
    "        test_id='00'+str(index)\n",
    "    elif(index<100):\n",
    "        test_id='0'+str(index)\n",
    "    else:\n",
    "        test_id=str(index)\n",
    "    test_id_l=[test_id]\n",
    "\n",
    "    #load image,label pairs and process it to chosen resolution and dimensions    \n",
    "    img_sys,label_sys,pixel_size,affine_tst= orig_img_dt(test_id_l,ret_affine=1)\n",
    "    cropped_img_sys,cropped_mask_sys = dt.preprocess_data(img_sys, label_sys, pixel_size)\n",
    "\n",
    "    #save the processed cropped img and its label\n",
    "    save_dir_tmp=str(cfg.data_path_tr_cropped)+str(test_id)+'/'\n",
    "    pathlib.Path(save_dir_tmp).mkdir(parents=True, exist_ok=True)\n",
    "    savefile_name=str(save_dir_tmp)+'img_cropped.npy' \n",
    "    np.save(savefile_name,cropped_img_sys)\n",
    "    savefile_name=str(save_dir_tmp)+'mask_cropped.npy' \n",
    "    np.save(savefile_name,cropped_mask_sys)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM4gyL2oulKmjJqK3+3z7It",
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
