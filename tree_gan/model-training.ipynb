{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model-training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"6iITVTcjGrm8","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"bf04e1f3-7602-43ad-d1b0-c2a27802bdc6","executionInfo":{"status":"ok","timestamp":1588299954580,"user_tz":240,"elapsed":33745,"user":{"displayName":"Daniel Csonth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64","userId":"10232999259256545758"}}},"source":["# Mount Google Drive\n","%%capture\n","from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive\"     # default location for the drive\n","\n","drive.mount(ROOT);           # we mount the google drive at /content/drive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hltsNIUwGs2-","colab":{}},"source":["# Set working directory\n","%%capture\n","%cd /content/drive/My Drive/restoration-mapper/task_driven_data_augmentation"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1588300003263,"user_tz":240,"elapsed":41984,"user":{"displayName":"Daniel Csonth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64","userId":"10232999259256545758"}},"id":"GYrtC8obIAAr","outputId":"f2f52358-da02-4a02-c4b0-6c52386c2c3b","colab":{"base_uri":"https://localhost:8080/","height":731}},"source":["!pip install tensorflow==1.8"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n","\u001b[K     |████████████████████████████████| 49.1MB 84kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.12.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.9.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.28.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.8.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.3.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.34.2)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (3.10.0)\n","Collecting tensorboard<1.9.0,>=1.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 43.1MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.1.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.18.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8) (46.1.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.2.1)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (1.0.1)\n","Collecting bleach==1.5.0\n","  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n","Collecting html5lib==0.9999999\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n","\u001b[K     |████████████████████████████████| 890kB 40.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: html5lib\n","  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=aa3dbaefa9d91696bc820f0effbc5924f7060676c948bf17e477e2efba65b69b\n","  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n","Successfully built html5lib\n","Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n","  Found existing installation: html5lib 1.0.1\n","    Uninstalling html5lib-1.0.1:\n","      Successfully uninstalled html5lib-1.0.1\n","  Found existing installation: bleach 3.1.4\n","    Uninstalling bleach-3.1.4:\n","      Successfully uninstalled bleach-3.1.4\n","  Found existing installation: tensorboard 2.2.1\n","    Uninstalling tensorboard-2.2.1:\n","      Successfully uninstalled tensorboard-2.2.1\n","  Found existing installation: tensorflow 2.2.0rc3\n","    Uninstalling tensorflow-2.2.0rc3:\n","      Successfully uninstalled tensorflow-2.2.0rc3\n","Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.8.0 tensorflow-1.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1588300015974,"user_tz":240,"elapsed":52812,"user":{"displayName":"Daniel Csonth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64","userId":"10232999259256545758"}},"id":"RZ1tigQMIehQ","outputId":"ab6d050a-1791-4727-d356-c62b513ffd40","colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["!pip install -r requirements.txt "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting matplotlib==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/09/530909669df3503caf1558544054fdbe2922d1f88a0a27820ee652c4fc58/matplotlib-2.2.0-cp36-cp36m-manylinux1_x86_64.whl (12.5MB)\n","\u001b[K     |████████████████████████████████| 12.5MB 269kB/s \n","\u001b[?25hCollecting nibabel==2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/ec/c4d49fb2aecb80d1c61f89542fdc0ba9686b232bc24f490caeba69d231b6/nibabel-2.1.0.tar.gz (3.6MB)\n","\u001b[K     |████████████████████████████████| 3.6MB 38.1MB/s \n","\u001b[?25hCollecting numpy==1.14.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/7d/348c5d8d44443656e76285aa97b828b6dbd9c10e5b9c0f7f98eff0ff70e4/numpy-1.14.1-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n","\u001b[K     |████████████████████████████████| 12.2MB 11.3MB/s \n","\u001b[?25hCollecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 143kB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.0)\n","Collecting array2gif\n","  Downloading https://files.pythonhosted.org/packages/42/f4/4dd66a8b65738ea8f2739a48d0e1a79e6a77c0cfb4b35a890eb9792dc861/array2gif-1.0.4-py3-none-any.whl\n","Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.0.1)\n","Collecting argparse\n","  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n","Collecting skimage\n","  Downloading https://files.pythonhosted.org/packages/3b/ee/edbfa69ba7b7d9726e634bfbeefd04b5a1764e9e74867ec916113eeaf4a1/skimage-0.0.tar.gz\n","\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1588300056938,"user_tz":240,"elapsed":3413,"user":{"displayName":"Daniel Csonth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64","userId":"10232999259256545758"}},"id":"TExx0ZMDa2vX","outputId":"131a1490-3109-4c7d-d473-431b6ff9aa58","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["!pip install array2gif"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting array2gif\n","  Using cached https://files.pythonhosted.org/packages/42/f4/4dd66a8b65738ea8f2739a48d0e1a79e6a77c0cfb4b35a890eb9792dc861/array2gif-1.0.4-py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from array2gif) (1.18.3)\n","Installing collected packages: array2gif\n","Successfully installed array2gif-1.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1588300059664,"user_tz":240,"elapsed":1157,"user":{"displayName":"Daniel Csonth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64","userId":"10232999259256545758"}},"id":"L7Zag0WcIPR_","outputId":"b3e48657-3c5c-4ede-ffee-04de9d7d1758","colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["1.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jeVhwS5BJcBR","colab":{}},"source":["import os\n","config=tf.ConfigProto()\n","config.gpu_options.allow_growth=True\n","config.allow_soft_placement=True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Uu_tUB8IKRGh","colab":{}},"source":["import matplotlib\n","matplotlib.use('Agg')\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","\n","#to make directories\n","import pathlib\n","\n","import sys\n","\n","from utils import *\n","\n","import argparse"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fXpK-mkyKWCY","colab":{}},"source":["class params:\n","  dataset = 'acdc'\n","  #no of training images\n","  no_of_tr_imgs = 'tr3' # Options include: ['tr1', 'tr3', 'tr5', 'tr15', 'tr40']\n","  #combination of training images\n","  comb_tr_imgs = 'c1' # Options include: ['c1', 'c2', 'c3', 'c4', 'c5']\n","\n","  #learning rate of seg unet\n","  lr_seg = 0.001\n","  # learning rate of generator\n","  lr_gen = 0.0001\n","  # learning rate of discriminator\n","  lr_disc = 0.0001\n","  # lat dim of z sample\n","  z_lat_dim = 100\n","\n","  # ra_en : 0 - disabled, 1 - enabled\n","  ra_en = 0\n","  # select gan type\n","  gan_type = 'gan' # Options include: ['lsgan', 'gan', 'wgan-gp','ngan']\n","  # beta value of Adam optimizer\n","  beta_val = 0.9\n","  # to enable the representation of labels with 1 hot encoding\n","  en_1hot = 1\n","\n","  # lamda factors\n","  # for segmenation loss term (lamda_dsc)\n","  lamda_dsc = 1\n","  # adversarial loss term (lamda_adv)\n","  lamda_adv = 1\n","  ### deformation field cGAN specific\n","  # for negative L1 loss on spatial transformation (per-pixel flow field/deformation field) term (lamda_l1_g)\n","  lamda_l1_g = 0.001\n","\n","  ### Intensity field cGAN specific\n","  # for negative L1 loss on transformation (additive intensity field) term (lamda_l1_i)\n","  lamda_l1_i = 0.001\n","\n","  #version of run\n","  ver = 0\n","\n","  #data aug - 0 - disabled, 1 - enabled\n","  data_aug_seg = 1 # Options include: [0,1]\n","\n","  # segmentation loss to optimize\n","  # 0 for weighted cross entropy, 1 for dice score loss\n","  dsc_loss = 0 # Options include: [0,1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8cqzpqbwnvoZ"},"source":["## Deformation Network"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qfnJ_KT5nul0","outputId":"54a8aa34-86de-4a7b-e475-c602a7ffeec4","colab":{"base_uri":"https://localhost:8080/","height":494},"executionInfo":{"status":"error","timestamp":1588300097324,"user_tz":240,"elapsed":23039,"user":{"displayName":"Daniel Csonth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64","userId":"10232999259256545758"}}},"source":["ra_en_val=params.ra_en\n","if(params.ra_en==1):\n","    params.ra_en=True\n","else:\n","    params.ra_en=False\n","\n","if params.dataset == 'acdc':\n","    #print('load acdc configs')\n","    import experiment_init.init_acdc as cfg\n","    import experiment_init.data_cfg_acdc as data_list\n","else:\n","    raise ValueError(params.dataset)\n","\n","######################################\n","# class loaders\n","# ####################################\n","#  load dataloader object\n","from dataloaders import dataloaderObj\n","dt = dataloaderObj(cfg)\n","\n","if params.dataset == 'acdc':\n","    #print('set acdc orig img dataloader handle')\n","    orig_img_dt=dt.load_acdc_imgs\n","\n","#  load model object\n","from models import modelObj\n","model = modelObj(cfg)\n","#  load f1_utils object\n","from f1_utils import f1_utilsObj\n","f1_util = f1_utilsObj(cfg,dt)\n","\n","######################################\n","#define save_dir for the model\n","save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n","\n","if(params.data_aug_seg==0):\n","    save_dir=str(save_dir)+'no_data_aug/'\n","    cfg.aug_en=params.data_aug_seg\n","else:\n","    save_dir=str(save_dir)+'with_data_aug/'\n","\n","save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n","         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n","         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n","\n","print('save_dir',save_dir)\n","######################################\n","\n","######################################\n","# load train and val images\n","train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n","#load train data cropped images directly\n","print('loading train imgs')\n","train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n","\n","if(params.no_of_tr_imgs=='tr1'):\n","    train_imgs_copy=np.copy(train_imgs)\n","    train_labels_copy=np.copy(train_labels)\n","    while(train_imgs.shape[2]<cfg.batch_size):\n","        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n","        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n","    del train_imgs_copy,train_labels_copy\n","\n","val_list = data_list.val_data()\n","#load both val data and its cropped images\n","print('loading val imgs')\n","val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n","\n","# # load unlabeled images\n","unl_list = data_list.unlabeled_data()\n","print('loading unlabeled imgs')\n","unlabeled_imgs=dt.load_acdc_cropped_img_labels(unl_list,label_present=0)\n","#print('unlabeled_imgs',unlabeled_imgs.shape)\n","\n","# get test list\n","print('get test imgs list')\n","test_list = data_list.test_data()\n","struct_name=cfg.struct_name\n","val_step_update=cfg.val_step_update\n","######################################\n","\n","######################################\n","\n","def get_samples(labeled_imgs,unlabeled_imgs):\n","    # sample z vectors from Gaussian Distribution\n","    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n","\n","    # sample Unlabeled data shuffled batch\n","    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n","\n","    # sample Labelled data shuffled batch\n","    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n","\n","    return z_samples,ld_img_batch,unld_img_batch\n","\n","def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n","    # plot deformed images for an fixed input image and different per-pixel flow vectors generated from sampled z values\n","    ld_img_tmp=np.zeros_like(ld_img_batch)\n","    # select one 2D image from the batch and apply different z's sampled over this selected image\n","    for i in range(0,20):\n","        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n","\n","    flow_vec,y_geo_deformed,z_cost=sess.run([ae['flow_vec'],ae['y_trans'],ae['z_cost']], feed_dict={ae['x_l']: ld_img_tmp, ae['z']:z_samples,\\\n","                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n","\n","    f1_util.plot_deformed_imgs(ld_img_tmp,y_geo_deformed,flow_vec,save_dir,index=index)\n","\n","    # Plot gif of all the deformed images generated for the fixed input image\n","    f1_util.write_gif_func(ip_img=y_geo_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)\n","\n","\n","######################################\n","# Define checkpoint file to save CNN architecture and learnt hyperparameters\n","checkpoint_filename='unet_'+str(params.dataset)\n","logs_path = str(save_dir)+'tensorflow_logs/'\n","best_model_dir=str(save_dir)+'best_model/'\n","######################################\n","\n","######################################\n","# Define deformation field generator model graph\n","ae = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n","                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n","                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n","                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)\n","\n","######################################\n","#  training parameters\n","start_epoch=0\n","n_epochs = 10000\n","disp_step=400\n","print_step=2000\n","# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n","seg_tr_limit=400\n","mean_f1_val_prev=0.1\n","threshold_f1=0.000001\n","pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n","######################################\n","\n","######################################\n","# define graph to compute deformed image given an per-pixel flow vector and input image\n","df_ae= model.deform_net()\n","######################################\n","\n","######################################\n","#writer for train summary\n","train_writer = tf.summary.FileWriter(logs_path)\n","#writer for dice score and val summary\n","dsc_writer = tf.summary.FileWriter(logs_path)\n","val_sum_writer = tf.summary.FileWriter(logs_path)\n","######################################\n","\n","######################################\n","# create a session and initialize variable to use the graph\n","sess = tf.Session(config=config)\n","sess.run(tf.global_variables_initializer())\n","# Save training data\n","saver = tf.train.Saver(max_to_keep=2)\n","######################################\n","\n","# Run for n_epochs\n","for epoch_i in range(start_epoch,n_epochs):\n","\n","    # sample z's from Gaussian Distribution\n","    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n","\n","    # sample Unlabeled shuffled batch\n","    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n","\n","    # sample Labelled shuffled batch\n","    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n","    if(cfg.aug_en==1):\n","        # Apply affine transformations\n","        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n","        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n","\n","    ld_img_batch_tmp=np.copy(ld_img_batch)\n","    # Compute 1 hot encoding of the segmentation mask labels\n","    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n","\n","    if(epoch_i>=seg_tr_limit):\n","        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n","        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n","        ld_label_batch_tmp=np.copy(ld_label_batch)\n","        ###########################\n","        ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n","        flow_vec,ld_img_batch=sess.run([ae['flow_vec'],ae['y_trans']],\\\n","                                    feed_dict={ae['x_l']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n","\n","        ld_label_batch=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch,df_ae['flow_v']:flow_vec})\n","        ld_label_batch=ld_label_batch[0]\n","\n","        ###########################\n","        #shuffle the quantity/number of images chosen from deformation cGAN augmented images and rest are original images with conventional affine transformations\n","        no_orig=np.random.randint(5, high=15)\n","        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n","        if(params.en_1hot==1):\n","            ld_label_batch[0:no_orig] = ld_label_batch_1hot[0:no_orig]\n","        else:\n","            ld_label_batch = np.argmax(ld_label_batch,axis=3)\n","            ld_label_batch[0:no_orig] = ld_label_batch_tmp[0:no_orig]\n","\n","        #Pick equal number of images from each category\n","        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n","        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n","\n","    elif(epoch_i<seg_tr_limit):\n","        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n","        ld_img_batch=ld_img_batch\n","        unld_img_batch=unld_img_batch\n","        ld_label_batch=ld_label_batch_1hot\n","\n","    if(epoch_i<seg_tr_limit):\n","        #Optimize only Segmentation Network for initial 500 epochs\n","        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n","                                   ae['select_mask']: False, ae['train_phase']: True})\n","\n","    if(epoch_i>seg_tr_limit):\n","        #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n","\n","        # update both Generator and Segmentation Net parameters in the framework using total loss value\n","        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n","                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n","        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n","        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch, ae['z']:z_samples,\\\n","                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n","\n","    if(epoch_i%val_step_update==0):\n","        train_writer.add_summary(train_summary, epoch_i)\n","        train_writer.flush()\n","\n","    if(epoch_i%val_step_update==0):\n","        ##Save the model with best DSC for Validation Image\n","        mean_f1_arr=[]\n","        f1_arr=[]\n","        for val_id_no in range(0,len(val_list)):\n","            val_img_crop_tmp=val_img_crop[val_id_no]\n","            val_label_crop_tmp=val_label_crop[val_id_no]\n","            val_label_orig_tmp=val_label_orig[val_id_no]\n","            pixel_size_val=pixel_val_list[val_id_no]\n","\n","            # Compute segmentation mask and dice_score for each validation subject\n","            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n","            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n","\n","            #concatenate dice scores of each val image\n","            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n","            f1_arr.append(f1_val[1:cfg.num_classes])\n","\n","        #avg mean over 2 val subjects\n","        mean_f1_arr=np.asarray(mean_f1_arr)\n","        mean_f1=np.mean(mean_f1_arr)\n","        f1_arr=np.asarray(f1_arr)\n","\n","        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n","            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n","            mean_f1_val_prev = mean_f1\n","            # to save the best model with maximum dice score over the entire n_epochs\n","            print(\"best model saved at epoch no. \", epoch_i)\n","            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n","            saver.save(sess, mp_best)\n","\n","        #calc. and save validation image dice summary\n","        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n","                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n","        val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n","        val_sum_writer.flush()\n","\n","    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n","        # model saved at last epoch\n","        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n","        saver.save(sess, mp)\n","        try:\n","            mp_best\n","        except NameError:\n","            mp_best=mp\n","\n","sess.close()\n","######################################\n","# restore best model and predict segmentations on test subjects\n","saver_new = tf.train.Saver()\n","sess_new = tf.Session(config=config)\n","saver_new.restore(sess_new, mp_best)\n","print(\"best model chkpt name\",mp_best)\n","print(\"Model restored\")\n","\n","#########################\n","# To compute inference on test images on the model that yields best dice score on validation images\n","f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n","#########################\n","# To plot the generated augmented images from the trained deformation cGAN\n","for j in range(0,5):\n","    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n","    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n","    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n","######################################\n","# To compute inference on validation images on the best model\n","save_dir_tmp=str(save_dir)+'/val_imgs/'\n","f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n","######################################\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["loss init\n","save_dir data_aug_seg/models/acdc/tr_deformation_cgan_unet/ra_en_0_gantype_gan/with_data_aug/lamda_dsc_1_lamda_adv_1_lamda_g_0.001/tr3/c1_v0/unet_model_beta1_0.9_lr_seg_0.001_lr_gen_0.0001_lr_disc_0.0001/\n","loading train imgs\n","(224, 224, 26)\n","(224, 224, 26)\n","loading val imgs\n","loading unlabeled imgs\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e30d6984c38c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0munl_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlabeled_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading unlabeled imgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0munlabeled_imgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_acdc_cropped_img_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munl_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_present\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;31m#print('unlabeled_imgs',unlabeled_imgs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/restoration-mapper/task_driven_data_augmentation/dataloaders.py\u001b[0m in \u001b[0;36mload_acdc_cropped_img_labels\u001b[0;34m(self, train_ids_list, label_present)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m#print(\"study_id\",study_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mimg_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path_tr_cropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/img_cropped.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mimg_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_present\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mmask_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path_tr_cropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/mask_cropped.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cI-JoaIAOeFl"},"source":["# Train Additive Intensity Field GAN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gGmOCYBzOi3g","colab":{}},"source":["ra_en_val=params.ra_en\n","if(params.ra_en==1):\n","    params.ra_en=True\n","else:\n","    params.ra_en=False\n","\n","\n","if params.dataset == 'acdc':\n","    #print('load acdc configs')\n","    import experiment_init.init_acdc as cfg\n","    import experiment_init.data_cfg_acdc as data_list\n","else:\n","    raise ValueError(params.dataset)\n","\n","######################################\n","# class loaders\n","# ####################################\n","#  load dataloader object\n","from dataloaders import dataloaderObj\n","dt = dataloaderObj(cfg)\n","\n","if params.dataset == 'acdc':\n","    #print('set acdc orig img dataloader handle')\n","    orig_img_dt=dt.load_acdc_imgs\n","\n","#  load model object\n","from models import modelObj\n","model = modelObj(cfg)\n","#  load f1_utils object\n","from f1_utils import f1_utilsObj\n","f1_util = f1_utilsObj(cfg,dt)\n","\n","######################################\n","#define save_dir for the model\n","save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n","\n","if(params.data_aug_seg==0):\n","    save_dir=str(save_dir)+'no_data_aug/'\n","    cfg.aug_en=params.data_aug_seg\n","else:\n","    save_dir=str(save_dir)+'with_data_aug/'\n","\n","save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n","         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n","         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n","\n","print('save_dir',save_dir)\n","######################################\n","\n","######################################\n","# load train and val images\n","train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n","# load train data cropped images directly\n","print('loading train imgs')\n","train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n","\n","if(params.no_of_tr_imgs=='tr1'):\n","    train_imgs_copy=np.copy(train_imgs)\n","    train_labels_copy=np.copy(train_labels)\n","    while(train_imgs.shape[2]<cfg.batch_size):\n","        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n","        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n","    del train_imgs_copy,train_labels_copy\n","\n","val_list = data_list.val_data()\n","# load both val data and its cropped images\n","print('loading val imgs')\n","val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n","\n","# load unlabeled images\n","unl_list = data_list.unlabeled_data()\n","print('loading unlabeled imgs')\n","unlabeled_imgs=dt.load_acdc_cropped_img_labels(unl_list,label_present=0)\n","\n","# get test list\n","print('get test imgs list')\n","test_list = data_list.test_data()\n","struct_name=cfg.struct_name\n","val_step_update=cfg.val_step_update\n","######################################\n","\n","######################################\n","\n","def get_samples(labeled_imgs,unlabeled_imgs):\n","    # sample z vectors from Gaussian Distribution\n","    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n","\n","    #sample Unlabeled data shuffled batch\n","    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n","\n","    #sample Labelled data shuffled batch\n","    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n","\n","    return z_samples,ld_img_batch,unld_img_batch\n","\n","def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n","    # plot intensity transformed images for an fixed input image and different sampled z values\n","    ld_img_tmp=np.zeros_like(ld_img_batch)\n","    # select one 2D image from the batch and apply different z's sampled over this selected image\n","    for i in range(0,20):\n","        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n","\n","    int_vec,y_int_deformed,z_cost=sess.run([ae['int_c1'],ae['y_int'],ae['z_cost']], feed_dict={ae['x']: ld_img_tmp, ae['z']:z_samples,\\\n","                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n","\n","    f1_util.plot_intensity_transformed_imgs(ld_img_tmp,y_int_deformed,int_vec,save_dir,index=index)\n","\n","    # Plot gif of all the transformed images generated for the fixed input image\n","    #f1_util.write_gif_func(ip_img=y_int_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)\n","\n","######################################\n","# Define checkpoint file to save CNN architecture and learnt hyperparameters\n","checkpoint_filename='unet_'+str(params.dataset)\n","logs_path = str(save_dir)+'tensorflow_logs/'\n","best_model_dir=str(save_dir)+'best_model/'\n","######################################\n","\n","######################################\n","# Define additive intensity field generator model graph\n","ae = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n","                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n","                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n","                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n","\n","######################################\n","#  training parameters\n","start_epoch=0\n","n_epochs = 10000\n","disp_step=400\n","print_step=2000\n","# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n","seg_tr_limit=400\n","mean_f1_val_prev=0.1\n","threshold_f1=0.00001\n","pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n","######################################\n","\n","######################################\n","# define graph to compute 1 hot encoding for an input label\n","df_ae= model.deform_net()\n","######################################\n","\n","######################################\n","#writer for train summary\n","train_writer = tf.summary.FileWriter(logs_path)\n","#writer for dice score and val summary\n","dsc_writer = tf.summary.FileWriter(logs_path)\n","val_sum_writer = tf.summary.FileWriter(logs_path)\n","######################################\n","\n","######################################\n","# create a session and initialize variable to use the graph\n","sess = tf.Session(config=config)\n","sess.run(tf.global_variables_initializer())\n","# Save training data\n","saver = tf.train.Saver(max_to_keep=2)\n","######################################\n","\n","# Run for n_epochs\n","for epoch_i in range(start_epoch,n_epochs):\n","\n","    # sample z's from Gaussian Distribution\n","    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n","\n","    # sample Unlabeled shuffled batch\n","    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n","\n","    # sample Labeled shuffled batch\n","    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n","\n","    if(cfg.aug_en==1):\n","        # Apply affine transformations\n","        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n","        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n","\n","    ld_img_batch_tmp=np.copy(ld_img_batch)\n","    # Compute 1 hot encoding of the segmentation mask labels\n","    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n","\n","    if(epoch_i>=seg_tr_limit):\n","        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n","        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n","        # Here, the labels do not change on application of intensity transformation since it is an additive operation\n","        ld_label_batch_tmp=np.copy(ld_label_batch)\n","        ###########################\n","        # use additive intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n","        _,ld_img_batch=sess.run([ae['int_c1'],ae['y_int']],\\\n","                                    feed_dict={ae['x']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n","        ld_label_batch=ld_label_batch_1hot\n","\n","        ###########################\n","        # shuffle the quantity/number of images chosen from intensity field cGAN augmented images and rest are original images with conventional affine transformations\n","        no_orig=np.random.randint(5, high=15)\n","        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n","        if(params.en_1hot==1):\n","            ld_label_batch = ld_label_batch_1hot\n","        else:\n","            ld_label_batch = ld_label_batch_tmp\n","\n","        #Pick equal number of images from each category\n","        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n","        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n","\n","    elif(epoch_i<seg_tr_limit):\n","        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n","        ld_img_batch=ld_img_batch\n","        unld_img_batch=unld_img_batch\n","        ld_label_batch=ld_label_batch_1hot\n","\n","    if(epoch_i<seg_tr_limit):\n","        #Optimize only Segmentation Network for initial 500 epochs\n","        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n","                                   ae['select_mask']: False, ae['train_phase']: True})\n","\n","    if(epoch_i>seg_tr_limit):\n","        #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n","\n","        # update both Generator and Segmentation Net parameters in the framework using total loss value\n","        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n","                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n","\n","        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n","        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['z']:z_samples,\\\n","                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n","\n","    if(epoch_i%val_step_update==0):\n","        train_writer.add_summary(train_summary, epoch_i)\n","        train_writer.flush()\n","\n","    if(epoch_i%val_step_update==0):\n","        ##Save the model with best DSC for Validation Image\n","        mean_f1_arr=[]\n","        f1_arr=[]\n","        for val_id_no in range(0,len(val_list)):\n","            val_img_crop_tmp=val_img_crop[val_id_no]\n","            val_label_crop_tmp=val_label_crop[val_id_no]\n","            val_label_orig_tmp=val_label_orig[val_id_no]\n","            pixel_size_val=pixel_val_list[val_id_no]\n","\n","            # Compute segmentation mask and dice_score for each validation subject\n","            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n","            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n","\n","            #concatenate dice scores of each val image\n","            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n","            f1_arr.append(f1_val[1:cfg.num_classes])\n","\n","        #avg mean over 2 val subjects\n","        mean_f1_arr = np.asarray(mean_f1_arr)\n","        mean_f1 = np.mean(mean_f1_arr)\n","        f1_arr = np.asarray(f1_arr)\n","\n","        if ((epoch_i%disp_step == 0) or (epoch_i==n_epochs-1)):\n","            print('mean_f1',epoch_i, mean_f1)\n","        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n","            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n","            mean_f1_val_prev = mean_f1\n","            # to save the best model with maximum dice score over the entire n_epochs\n","            print(\"best model saved at epoch no. \", epoch_i)\n","            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n","            saver.save(sess, mp_best)\n","\n","        #calc. and save validation image dice summary\n","        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n","                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n","\n","    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n","        # model saved at last epoch\n","        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n","        saver.save(sess, mp)\n","        try:\n","            mp_best\n","        except NameError:\n","            mp_best=mp\n","\n","sess.close()\n","######################################\n","# restore best model and predict segmentations on test subjects\n","saver_new = tf.train.Saver()\n","sess_new = tf.Session(config=config)\n","saver_new.restore(sess_new, mp_best)\n","print(\"best model chkpt\",mp_best)\n","print(\"Model restored\")\n","\n","#########################\n","# To compute inference on test images on the model that yields best dice score on validation images\n","f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n","#########################\n","# To plot the generated augmented images from the trained deformation cGAN\n","for j in range(0,5):\n","    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n","    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n","    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n","######################################\n","# To compute inference on validation images on the best model\n","save_dir_tmp=str(save_dir)+'/val_imgs/'\n","f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n","######################################"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Htfi8elnNp4c"},"source":["# Train Unet with trained GANs"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":24877,"status":"error","timestamp":1588173382149,"user":{"displayName":"David Paolella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhyvQ2T2w5gaFLerdln3UycYDOGbTDuyWch0kmG=s64","userId":"06299863553633725725"},"user_tz":240},"id":"W_67bO43M4_R","outputId":"b06d2d3b-0e1c-483a-ea76-baf68b1f7e8d","colab":{"base_uri":"https://localhost:8080/","height":609}},"source":["ra_en_val=params.ra_en\n","if(params.ra_en==1):\n","    params.ra_en=True\n","else:\n","    params.ra_en=False\n","\n","if params.dataset == 'acdc':\n","    print('load acdc configs')\n","    import experiment_init.init_acdc as cfg\n","    import experiment_init.data_cfg_acdc as data_list\n","else:\n","    raise ValueError(params.dataset)\n","\n","######################################\n","# class loaders\n","# ####################################\n","#  load dataloader object\n","from dataloaders import dataloaderObj\n","dt = dataloaderObj(cfg)\n","\n","if params.dataset == 'acdc':\n","    print('set acdc img dataloader handle')\n","    orig_img_dt=dt.load_acdc_imgs\n","\n","#  load model object\n","from models import modelObj\n","model = modelObj(cfg)\n","\n","#  load f1_utils object\n","from f1_utils import f1_utilsObj\n","f1_util = f1_utilsObj(cfg,dt)\n","\n","######################################\n","#define save_dir for the model\n","proj_save_name='tr_deform_and_int_cgans_data_aug/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)\n","\n","if(params.data_aug_seg==0):\n","    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/no_data_aug/'\n","    cfg.aug_en=params.data_aug_seg\n","else:\n","    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/with_data_aug/'\n","\n","save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+\\\n","         '_lamda_g_'+str(params.lamda_l1_g)+'_lamda_i_'+str(params.lamda_l1_i)+\\\n","         '/'+str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+'/unet_model_dsc_loss_'+str(params.dsc_loss)+'_lr_seg_'+str(params.lr_seg)+'/'\n","print('save_dir',save_dir)\n","######################################\n","\n","######################################\n","# load train and val images\n","train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n","#print(train_list)\n","#load train data cropped images directly\n","print('loading train imgs')\n","train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n","\n","if(params.no_of_tr_imgs=='tr1'):\n","    train_imgs_copy=np.copy(train_imgs)\n","    train_labels_copy=np.copy(train_labels)\n","    while(train_imgs.shape[2]<cfg.batch_size):\n","        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n","        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n","    del train_imgs_copy,train_labels_copy\n","\n","val_list = data_list.val_data()\n","#print(val_list)\n","#load both val data and its cropped images\n","print('loading val imgs')\n","val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n","#print(pixel_val_list)\n","\n","# get test list\n","print('get test imgs list')\n","test_list = data_list.test_data()\n","struct_name=cfg.struct_name\n","val_step_update=cfg.val_step_update\n","######################################\n","\n","######################################\n","# Define checkpoint file to save CNN architecture and learnt hyperparameters\n","checkpoint_filename='unet_'+str(params.dataset)\n","logs_path = str(save_dir)+'tensorflow_logs/'\n","best_model_dir=str(save_dir)+'best_model/'\n","######################################\n","\n","########################################################################\n","#load deformation field generator net\n","########################################################################\n","# Define the model graph\n","tf.reset_default_graph()\n","ae_geo = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n","                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n","                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n","                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)\n","\n","# define model path\n","model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n","\n","if(params.data_aug_seg==0):\n","    model_path=str(model_path)+'no_data_aug/'\n","    cfg.aug_en=params.data_aug_seg\n","else:\n","    model_path=str(model_path)+'with_data_aug/'\n","\n","model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n","         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n","         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n","\n","mp=get_max_chkpt_file(model_path)\n","print('loading deformation field cGAN checkpoint file',mp)\n","# create a session and load the parameters learned\n","saver_geo = tf.train.Saver(max_to_keep=2)\n","sess_geo = tf.Session(config=config)\n","saver_geo.restore(sess_geo,mp)\n","######################################\n","\n","########################################################################\n","#load additive intensity field generator net\n","########################################################################\n","# Define the model graph\n","tf.reset_default_graph()\n","ae_int = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n","                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n","                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n","                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n","\n","# define model path\n","model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n","\n","if(params.data_aug_seg==0):\n","    model_path=str(model_path)+'no_data_aug/'\n","    cfg.aug_en=params.data_aug_seg\n","else:\n","    model_path=str(model_path)+'with_data_aug/'\n","\n","model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n","         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n","         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n","\n","mp=get_max_chkpt_file(model_path)\n","print('loading additive intensity field cGAN checkpoint file ',mp)\n","# create a session and load the parameters learned\n","saver_int = tf.train.Saver(max_to_keep=2)\n","sess_int = tf.Session(config=config)\n","saver_int.restore(sess_int,mp)\n","\n","######################################\n","\n","######################################\n","#  training parameters\n","start_epoch=0\n","n_epochs = 10000\n","disp_step=500\n","mean_f1_val_prev=0.1\n","threshold_f1=0.00001\n","debug_en=0\n","pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n","######################################\n","\n","######################################\n","# define current graph - unet\n","tf.reset_default_graph()\n","ae = model.unet(learn_rate_seg=params.lr_seg,en_1hot=params.en_1hot,dsc_loss=params.dsc_loss)\n","######################################\n","\n","######################################\n","# define deformations net for labels\n","df_ae= model.deform_net()\n","######################################\n","\n","######################################\n","#writer for train summary\n","train_writer = tf.summary.FileWriter(logs_path)\n","#writer for dice score and val summary\n","dsc_writer = tf.summary.FileWriter(logs_path)\n","val_sum_writer = tf.summary.FileWriter(logs_path)\n","######################################\n","\n","######################################\n","# create a session and initialize variable to use the graph\n","sess = tf.Session(config=config)\n","sess.run(tf.global_variables_initializer())\n","# Save training data\n","saver = tf.train.Saver(max_to_keep=2)\n","######################################\n","\n","# Run for n_epochs\n","for epoch_i in range(start_epoch,n_epochs):\n","\n","    # sample z's from Gaussian Distribution\n","    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n","\n","    #sample Labelled data shuffled batch\n","    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n","    if(cfg.aug_en==1):\n","        # Apply affine transformations\n","        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n","\n","    ld_img_batch_orig_tmp=np.copy(ld_img_batch)\n","    ld_label_batch_orig_tmp=np.copy(ld_label_batch)\n","    # Compute 1 hot encoding of the segmentation mask labels\n","    ld_label_batch_orig_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp})\n","\n","    ############################\n","    ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n","    flow_vec,ld_img_batch_geo=sess_geo.run([ae_geo['flow_vec'],ae_geo['y_trans']],\\\n","                                feed_dict={ae_geo['x_l']: ld_img_batch_orig_tmp, ae_geo['z']:z_samples, ae_geo['train_phase']: False})\n","\n","    ld_label_batch_geo=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp,df_ae['flow_v']:flow_vec})\n","    ld_label_batch_geo=ld_label_batch_geo[0]\n","\n","    ############################\n","    # use additive Intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n","    int_c1,ld_img_batch_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_orig_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n","    ld_label_batch_int = ld_label_batch_orig_1hot\n","\n","    ############################\n","    # use additive intensity field cGAN over augmented images generated from deformation field cGAN to create augmented images \\\n","    # that have both spatial deformations and intensity transformations applied in them\n","    ld_img_batch_geo_tmp=np.copy(ld_img_batch_geo)\n","    int_c1,ld_img_batch_geo_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_geo_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n","    ld_label_batch_geo_int = np.copy(ld_label_batch_geo)\n","\n","    # shuffle the quantity/number of images chosen from \n","    # deformation field cGAN --> no_g,\n","    # intensity field cGAN   --> no_i,\n","    # both cGANs             --> no_b,\n","    # and rest (batch_size - (no_g+no_i+no_b)) are original images with conventional affine transformations.\n","    no_g=np.random.randint(1, high=5)\n","    no_i=np.random.randint(5, high=10)\n","    no_b=np.random.randint(10, high=15)\n","\n","    ld_img_batch=ld_img_batch_orig_tmp\n","    ld_label_batch=ld_label_batch_orig_1hot\n","\n","    ld_img_batch[0:no_g] = ld_img_batch_geo[0:no_g]\n","    ld_label_batch[0:no_g] = ld_label_batch_geo[0:no_g]\n","    ld_img_batch[no_g:no_i] = ld_img_batch_int[no_g:no_i]\n","    ld_label_batch[no_g:no_i] = ld_label_batch_int[no_g:no_i]\n","    ld_img_batch[no_i:no_b] = ld_img_batch_geo_int[no_i:no_b]\n","    ld_label_batch[no_i:no_b] = ld_label_batch_geo_int[no_i:no_b]\n","\n","    #Optimer over this batch of images\n","    train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n","                               ae['select_mask']: False, ae['train_phase']: True})\n","\n","    if(epoch_i%val_step_update==0):\n","        train_writer.add_summary(train_summary, epoch_i)\n","        train_writer.flush()\n","\n","    if(epoch_i%val_step_update==0):\n","        ##Save the model with best DSC for Validation Image\n","        mean_f1_arr=[]\n","        f1_arr=[]\n","        for val_id_no in range(0,len(val_list)):\n","            val_img_crop_tmp=val_img_crop[val_id_no]\n","            val_label_crop_tmp=val_label_crop[val_id_no]\n","            val_label_orig_tmp=val_label_orig[val_id_no]\n","            pixel_size_val=pixel_val_list[val_id_no]\n","\n","            # Compute segmentation mask and dice_score for each validation subject\n","            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n","            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n","\n","            #concatenate dice scores of each val image\n","            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n","            f1_arr.append(f1_val[1:cfg.num_classes])\n","\n","        #avg mean over 2 val subjects\n","        mean_f1_arr=np.asarray(mean_f1_arr)\n","        mean_f1=np.mean(mean_f1_arr)\n","        f1_arr=np.asarray(f1_arr)\n","\n","        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n","            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n","            mean_f1_val_prev = mean_f1\n","\n","            # to save the best model with maximum dice score over the entire n_epochs\n","            print(\"best model saved at epoch no. \", epoch_i)\n","            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n","            saver.save(sess, mp_best)\n","\n","        #calc. and save validation image dice summary\n","        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n","                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n","        val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n","        val_sum_writer.flush()\n","\n","    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n","        # model saved at last epoch\n","        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n","        saver.save(sess, mp)\n","        try:\n","            mp_best\n","        except NameError:\n","            mp_best=mp\n","\n","sess.close()\n","######################################\n","# restore best model and predict segmentations on test subjects\n","saver_new = tf.train.Saver()\n","sess_new = tf.Session(config=config)\n","saver_new.restore(sess_new, mp_best)\n","print(\"best model chkpt\",mp_best)\n","print(\"Model restored\")\n","\n","#########################\n","# To compute inference on test images on the model that yields best dice score on validation images\n","f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n","######################################\n","# To compute inference on validation images on the best model\n","save_dir_tmp=str(save_dir)+'/val_imgs/'\n","f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n","######################################"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load acdc configs\n","set acdc img dataloader handle\n","loss init\n","save_dir data_aug_seg/models/acdc/tr_deform_and_int_cgans_data_aug/ra_en_0_gantype_gan/with_data_aug/lamda_dsc_1_lamda_adv_1_lamda_g_0.001_lamda_i_0.001/tr3/c1_v0/unet_model_dsc_loss_0_lr_seg_0.001/\n","loading train imgs\n","loading val imgs\n","get test imgs list\n","D ra_off sigmoid loss\n","G ra_off sigmoid loss\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["-2\n","data_aug_seg/models/acdc/tr_deformation_cgan_unet/ra_en_0_gantype_gan/with_data_aug/lamda_dsc_1_lamda_adv_1_lamda_g_0.001/tr3/c1_v0/unet_model_beta1_0.9_lr_seg_0.001_lr_gen_0.0001_lr_disc_0.0001/\n","<generator object walk at 0x7f63c3f32620>\n"],"name":"stdout"},{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-84931727a230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'lamda_dsc_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_dsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_lamda_adv_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_lamda_g_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_l1_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_tr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomb_tr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_v'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m         \u001b[0;34m'/unet_model_beta1_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_lr_seg_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_seg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_lr_gen_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_lr_disc_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_disc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_max_chkpt_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading deformation field cGAN checkpoint file'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# create a session and load the parameters learned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/task_driven_data_augmentation/utils.py\u001b[0m in \u001b[0;36mget_max_chkpt_file\u001b[0;34m(model_path, min_ep)\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mchkpt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mmin_ep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_ep_no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mfin_chkpt_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\.meta$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchkpt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfin_chkpt_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'chkpt_max' referenced before assignment"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aQSIfVO4TuWI","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}