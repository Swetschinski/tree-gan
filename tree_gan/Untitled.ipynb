{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#to make directories\n",
    "import pathlib\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx = np.load(\"data/gan_processed_data/lab_x_mini.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_filters=[1, 16, 32, 64, 128, 256]\n",
    "z_lat_dim=100\n",
    "lat_dim=128\n",
    "img_size_x = 16\n",
    "img_size_y = 16\n",
    "batch_size = 20\n",
    "num_channels = 1\n",
    "num_classes = 2\n",
    "en_1hot = 0\n",
    "std_init=0.01\n",
    "SEED=1\n",
    "acti='xavier'\n",
    "intl=tf.truncated_normal_initializer(stddev=std_init, seed=SEED)\n",
    "interp_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_layer(ip_layer, method=0, scale_factor=2, dim_list=None):\n",
    "    '''\n",
    "    2D upsampling layer with default image scale factor of 2.\n",
    "    ip_layer : input feature map layer\n",
    "    method = 0 --> Bilinear Interpolation\n",
    "             1 --> Nearest Neighbour\n",
    "             2 --> Bicubic Interpolation\n",
    "    scale_factor : factor by which we want to upsample current resolution\n",
    "    '''\n",
    "    if(dim_list!=None):\n",
    "        prev_height = dim_list[1]\n",
    "        prev_width = dim_list[2]\n",
    "    else:\n",
    "        prev_height = ip_layer.get_shape().as_list()[1]\n",
    "        prev_width = ip_layer.get_shape().as_list()[2]\n",
    "\n",
    "    new_height = int(round(prev_height * scale_factor))\n",
    "    new_width = int(round(prev_width * scale_factor))\n",
    "\n",
    "    op = tf.image.resize_images(images=ip_layer,size=[new_height,new_width],method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " def conv2d_layer(ip_layer,    # The previous/input layer.\n",
    "                 name,                 # Name of the conv layer\n",
    "                 bias_init=0,          # Constant bias value for initialization\n",
    "                 kernel_size=(3,3),    # Width and height of each filter.\n",
    "                 strides=(1,1),        # stride value of the filter\n",
    "                 num_filters=32,       # Number of output filters.\n",
    "                 padding='SAME',       # Padding - SAME for zero padding - i/p and o/p of conv. have same dimensions\n",
    "                 use_bias=True,        #to use bias or not\n",
    "                 use_relu=True,        # Use relu as activation function\n",
    "                 use_batch_norm=False,# use batch norm on layer before passing to activation function\n",
    "                 use_conv_stride=False,  # Use 2x2 max-pooling - obtained by convolution with stride 2.\n",
    "                 training_phase=True,   # Training Phase\n",
    "                 scope_name=None,      # scope name for batch norm\n",
    "                 acti_type='xavier',   # weight and bias variable initializer type\n",
    "                 dilated_conv=False,   # dilated convolution enbale/disable\n",
    "                 dilation_factor=1):   # dilation factor\n",
    "        '''\n",
    "        Standard 2D convolutional layer\n",
    "        '''\n",
    "        # Num. channels in prev. layer.\n",
    "        prev_layer_no_filters = ip_layer.get_shape().as_list()[-1]\n",
    "\n",
    "        weight_shape = [kernel_size[0], kernel_size[1], prev_layer_no_filters, num_filters]\n",
    "        bias_shape = [num_filters]\n",
    "\n",
    "        strides_augm = [1, strides[0], strides[1], 1]\n",
    "\n",
    "        if(scope_name==None):\n",
    "            scope_name=str(name)+'_bn'\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "\n",
    "            weights = self.get_weight_variable(weight_shape, name='W',acti_type=acti_type)\n",
    "            if(use_bias==True):\n",
    "                biases = self.get_bias_variable(bias_shape, name='b', init_bias_val=bias_init)\n",
    "\n",
    "            if(dilated_conv==True):\n",
    "                op_layer = tf.nn.atrous_conv2d(ip_layer, filters=weights, rate=dilation_factor, padding=padding, name=name)\n",
    "            else:\n",
    "                if(use_conv_stride==False):\n",
    "                    op_layer = tf.nn.conv2d(ip_layer, filter=weights, strides=strides_augm, padding=padding)\n",
    "                else:\n",
    "                    op_layer = tf.nn.conv2d(input=ip_layer, filter=weights, strides=[1, 2, 2, 1], padding=padding)\n",
    "\n",
    "            #Add bias\n",
    "            if(use_bias==True):\n",
    "                op_layer = tf.nn.bias_add(op_layer, biases)\n",
    "\n",
    "            if(use_batch_norm==True):\n",
    "                op_layer = self.batch_norm_layer(ip_layer=op_layer,name=scope_name,training=training_phase)\n",
    "            if(use_relu==True):\n",
    "                op_layer = tf.nn.relu(op_layer)\n",
    "\n",
    "            # Add Tensorboard summaries\n",
    "            #_add_summaries(op_layer, weights, biases)\n",
    "\n",
    "        #return op_layer,weights,biases\n",
    "        return op_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Generator - FCN variables\n",
    "gen_c1_weights = tf.get_variable(name=\"gen_c1_weights\",shape=[z_lat_dim,z_hid_dim], initializer=intl)\n",
    "gen_c1_biases = tf.get_variable(name=\"gen_c1_biases\",shape=[z_hid_dim], initializer=tf.constant_initializer(value=0))\n",
    "\n",
    "#Discriminator - FCN variables\n",
    "fcn_c1_weights = tf.get_variable(name=\"fcn_c1_weights\",shape=[hid_dim, latent_dim], initializer=intl)\n",
    "fcn_c1_biases = tf.get_variable(name=\"fcn_c1_biases\",shape=[latent_dim], initializer=tf.constant_initializer(value=0))\n",
    "fcn_c2_weights = tf.get_variable(name=\"fcn_c2_weights\",shape=[latent_dim, latent_dim], initializer=intl)\n",
    "fcn_c2_biases = tf.get_variable(name=\"fcn_c2_biases\",shape=[latent_dim], initializer=tf.constant_initializer(value=0))\n",
    "fcn_c3_weights = tf.get_variable(name=\"fcn_c3_weights\",shape=[latent_dim,1], initializer=intl)\n",
    "fcn_c3_biases = tf.get_variable(name=\"fcn_c3_biases\",shape=[1], initializer=tf.constant_initializer(value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L: this will likely need to be changed along with the others. Original value is 4*4 which is what we have for the deformation\n",
    "hid_dim=int(img_size_x*img_size_y*no_filters[4]/(4*4))\n",
    "latent_dim=lat_dim\n",
    "\n",
    "#L: changing this to 4*4 instead of 32*32 based on our reduction in dimensionality factor\n",
    "z_hid_dim=int(img_size_x*img_size_y*no_filters[4]/(4*4))\n",
    "#L: based on note on the top of the Generator network, dim_x is supposed to be the dimensions of the downsampled image,\n",
    "#4x4 in the case of JB's unet. Setting this to img size/4 for now. previously was imgsize/32\n",
    "dim_x = int(img_size_x/4)\n",
    "\n",
    "# Placeholders\n",
    "# input to the network\n",
    "z = tf.placeholder(tf.float32, shape=[batch_size, z_lat_dim], name='z')\n",
    "x_l = tf.placeholder(tf.float32, shape=[batch_size, img_size_x, img_size_y, num_channels], name='x_l')\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_x, img_size_y, num_channels], name='x')\n",
    "x_unl = tf.placeholder(tf.float32, shape=[None, img_size_x, img_size_y, num_channels], name='x_unl')\n",
    "if(en_1hot==1):\n",
    "    y_l = tf.placeholder(tf.float32, shape=[None, img_size_x, img_size_y, num_classes], name='y_l')\n",
    "else:\n",
    "    y_l = tf.placeholder(tf.int32, shape=[None, img_size_x, img_size_y], name='y_l')\n",
    "select_mask = tf.placeholder(tf.bool, name='select_mask')\n",
    "train_phase = tf.placeholder(tf.bool, name='train_phase')\n",
    "if(en_1hot==0):\n",
    "    y_l_onehot=tf.one_hot(y_l,depth=num_classes)\n",
    "else:\n",
    "    y_l_onehot=y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4, 4, 128)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-670311dc17af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mscale_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgen_up5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupsample_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_fcn_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterp_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_up5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mgen_c5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv2d_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_up5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gen_c5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs_de\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfs_de\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_filters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_relu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_batch_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_phase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_phase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_c5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "## Generator Network\n",
    "############################################\n",
    "# Dense layer + Reshape reshape to down sampled image dimensions\n",
    "gen_fcn_c1 = tf.matmul(z, gen_c1_weights) + gen_c1_biases\n",
    "gen_fcn_relu_c1 = tf.nn.relu(gen_fcn_c1)\n",
    "gen_fcn_reshaped = tf.reshape(gen_fcn_relu_c1 ,[-1,dim_x,dim_x,no_filters[4]])\n",
    "print(gen_fcn_reshaped.shape)# Level 5 - Upsampling layer + Conv. layer\n",
    "\n",
    "fs_de=2\n",
    "scale_val=2\n",
    "gen_up5 = upsample_layer(ip_layer=gen_fcn_reshaped, method=interp_val, scale_factor=scale_val)\n",
    "print(gen_up5.shape)\n",
    "gen_c5 = conv2d_layer(ip_layer=gen_up5,name='gen_c5', kernel_size=(fs_de,fs_de),num_filters=no_filters[4],use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "print(gen_c5.shape)\n",
    "\n",
    "# Level 4\n",
    "gen_up4 = upsample_layer(ip_layer=gen_c5, method=interp_val, scale_factor=scale_val)\n",
    "gen_c4 = conv2d_layer(ip_layer=gen_up4,name='gen_c4', kernel_size=(fs_de,fs_de),num_filters=no_filters[3],use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "print(gen_c4.shape)\n",
    "\n",
    "# Level 3\n",
    "gen_up3 = upsample_layer(ip_layer=gen_c4, method=interp_val, scale_factor=scale_val)\n",
    "gen_c3 = conv2d_layer(ip_layer=gen_up3,name='gen_c3', kernel_size=(fs_de,fs_de),num_filters=no_filters[2],use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "print(gen_c3.shape)\n",
    "\n",
    "# Level 2\n",
    "gen_up2 = upsample_layer(ip_layer=gen_c3, method=interp_val, scale_factor=scale_val)\n",
    "gen_c2 = conv2d_layer(ip_layer=gen_up2,name='gen_c2', kernel_size=(fs_de,fs_de),num_filters=no_filters[1],use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "print(gen_c2.shape)\n",
    "\n",
    "# Level 1\n",
    "gen_up1 = upsample_layer(ip_layer=gen_c2, method=interp_val, scale_factor=scale_val)\n",
    "gen_c1 = conv2d_layer(ip_layer=gen_up1,name='gen_c1', kernel_size=(fs_de,fs_de),num_filters=no_filters[1],use_relu=False, use_batch_norm=False, training_phase=train_phase)\n",
    "print(gen_c1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Conv. ops on input image\n",
    "        conv_1a = layers.conv2d_layer(ip_layer=x_l,name='conv_1a',num_filters=no_filters[1], use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "        conv_1b = layers.conv2d_layer(ip_layer=conv_1a,name='conv_1b',num_filters=no_filters[1], use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "\n",
    "        # Concatenate features obtained by conv. ops on image and on 'z'\n",
    "        gen_cat=tf.concat((gen_c1,conv_1b),axis=3)\n",
    "\n",
    "        # More Conv. ops on concatenated feature maps\n",
    "        conv_1c = layers.conv2d_layer(ip_layer=gen_cat,name='conv_1c',num_filters=no_filters[1], use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "        conv_1d = layers.conv2d_layer(ip_layer=conv_1c,name='conv_1d',num_filters=no_filters[1], use_relu=True, use_batch_norm=True, training_phase=train_phase)\n",
    "        conv_1e = layers.conv2d_layer(ip_layer=conv_1d,name='conv_1e',num_filters=2, use_relu=False, use_batch_norm=False, training_phase=train_phase)\n",
    "\n",
    "        flow_vec = conv_1e\n",
    "\n",
    "        # apply flow vector on the input image to get non-affine transformed image\n",
    "        y_trans=tf.contrib.image.dense_image_warp(image=x_l,flow=flow_vec,name='dense_image_warp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
