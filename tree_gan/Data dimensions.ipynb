{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                    \u001b[31mlosses.py\u001b[m\u001b[m*\r\n",
      "Untitled.ipynb               model-training.ipynb\r\n",
      "create_cropped_imgs_acdc.py  \u001b[31mmodels.py\u001b[m\u001b[m*\r\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m/                        preprocessing.ipynb\r\n",
      "\u001b[1m\u001b[36mdata_aug_seg\u001b[m\u001b[m/                requirements.txt\r\n",
      "\u001b[31mdataloaders.py\u001b[m\u001b[m*              test.txt\r\n",
      "\u001b[1m\u001b[36mexperiment_init\u001b[m\u001b[m/             \u001b[1m\u001b[36mtrain_model\u001b[m\u001b[m/\r\n",
      "\u001b[31mf1_utils.py\u001b[m\u001b[m*                 \u001b[31mutils.py\u001b[m\u001b[m*\r\n",
      "\u001b[31mlayers_bn.py\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lab_x_mini = np.load('data/gan_processed_data_original/lab_x_mini.npy')\n",
    "lab_y_mini = np.load('data/gan_processed_data_original/lab_y_mini.npy')\n",
    "unlab_x_mini = np.load('data/gan_processed_data_original/unlab_x_mini.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 24, 16, 16, 16)\n",
      "(5, 14, 14)\n",
      "(10, 24, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(lab_x_mini.shape)\n",
    "print(lab_y_mini.shape)\n",
    "print(unlab_x_mini.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am just adjusting the data Lucien created to match that of their network:\n",
    "1. The multiple images stacked on top of each other is their last dimension - whereas in the npy from Lucien it is the first\n",
    "    - this is something that we should fix at the data generation point this is just a patch that can be removed if Lucien regenarates the data concatenating it on the last dimension\n",
    "2. I am picking one of our time dimensions\n",
    "3. I am picking one of our 16 bands for now - haven't gotten to seeing how the code would handle it if I set num_channels = 16, so want to just get it to run like this first\n",
    "4. I am removing a pixel around the rim - not sure why our inputs are 16x16 but our masks are 14x14, but don't want that to trip it up for now\n",
    "    - though they have some mechanism for fixing this in utils.load_val_images, where they append 0's to match the image sizes, but not sure why their image dimensions don't match either... and that part is also commented out for now\n",
    "5. we might have to adjust the size of this tiny toy dataset to be a little bit bigger\n",
    " - see my comment titled: \"#D: we might have to adjust this if our mini sample is too small compared to batch size\" \n",
    "     - I got rid of code that would duplicate data if the input dataset is too small, so if you get far enough in the training this might become a problem \n",
    "     - so I am letting you know here so you know that is the problem when you get to an error that might be caused by it / maybe = even better: we should just feed it a little bit of a bigger dataset. The batch_size = 20, so let's jsut feed it more than that - I think we will do that anyway, we are not connerned about proving that it works with a super tiny training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_x_mini = np.moveaxis(lab_x_mini,0,-1)[0,1:-1,1:-1,3,:]\n",
    "lab_y_mini = np.moveaxis(lab_y_mini,0,-1)\n",
    "unlab_x_mini = np.moveaxis(unlab_x_mini,0,-1)[0,1:-1,1:-1,3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/gan_processed_data/lab_x_mini.npy', lab_x_mini)\n",
    "np.save('data/gan_processed_data/lab_y_mini.npy', lab_y_mini)\n",
    "np.save('data/gan_processed_data/unlab_x_mini.npy', unlab_x_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
